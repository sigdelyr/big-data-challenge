{
  "paragraphs": [
    {
      "title": "",
      "text": "%pyspark\n# Read in data from S3 Buckets\nfrom pyspark import SparkFiles\nurl \u003d\"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Home_v1_00.tsv.gz\"\nspark.sparkContext.addFile(url)\n\nhome_df \u003d spark.read.option(\"header\", \"true\").csv(\"s3a://amazon-reviews-pds/tsv/amazon_reviews_us_Home_v1_00.tsv.gz\", inferSchema\u003dTrue, sep\u003d\"\\t\")\n\n# Show DataFrame\nhome_df.show()",
      "user": "",
      "dateUpdated": "Dec 22, 2019 1:27:35 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|        review_date|\n+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n|         US|   33670092|R1UUISQ1GKOJTI|B00EE62UAE|     583436067|Trademark Home Po...|            Home|          1|            0|          0|   N|                Y|                 Run|Don\u0027t buy it clap...|2015-08-31 00:00:00|\n|         US|   13726692|R1HOJ9WE8VCVOD|B001APXO5C|     465035091|O2-Cool 10-Inch P...|            Home|          5|            9|          9|   N|                Y|Love it, really c...|Love this ,I boug...|2015-08-31 00:00:00|\n|         US|   50131396| RDNGVXMWQN2TN|B002HFDLCK|     136507891|Hoover Vacuum Cle...|            Home|          5|            0|          0|   N|                Y|          Five Stars|Nice style, color...|2015-08-31 00:00:00|\n|         US|   16046884|R3OM9COQMVTDJ2|B00PL9EFPQ|     631238459|Banksy Pile of Ri...|            Home|          2|            0|          0|   N|                Y|Love Banksy\u0027s wor...|Meeeh. Love Banks...|2015-08-31 00:00:00|\n|         US|   11417282|R3OFUQVR4Y80Q9|B00B5TPVQS|     190431573|SkyScan Atomic Wa...|            Home|          4|            0|          0|   N|                N|A silent second h...|Review by John Cr...|2015-08-31 00:00:00|\n|         US|   48013430|R2GD25SBBGRKPO|B00NQDGHDC|     124050883|Mellanni Bed Shee...|            Home|          5|            0|          0|   N|                Y|I am very pleased...|I am very pleased...|2015-08-31 00:00:00|\n|         US|    7341516|R3RRSLYKVWH9WB|B00I3BYEXM|     933053612|Hippie Hobo Sling...|            Home|          5|            0|          0|   N|                Y|          Five Stars|LOVE THIS SO VERY...|2015-08-31 00:00:00|\n|         US|   20696954|R2HMFAGJJU6NT3|B008QZD7RY|      77515396|OluKai Hokua Sand...|            Home|          5|            0|          0|   N|                Y|          Five Stars|           Love them|2015-08-31 00:00:00|\n|         US|   28241302|R2QDRZATHBY4GY|B00TQ6MXE0|     267158600|Melrose Ivory Ant...|            Home|          1|            0|          0|   N|                Y|Not the color I e...|This is a nice sh...|2015-08-31 00:00:00|\n|         US|   45444347|R107946YZK57Q2|B004O39RJ4|     473994651|Home Basics 6-Pie...|            Home|          2|            0|          0|   N|                Y|Two mugs came chi...|Two mugs came chi...|2015-08-31 00:00:00|\n|         US|   15080335|R31EK6FUI5YAL1|B003LZ09C0|     945333576|La Crosse Technol...|            Home|          5|            0|          0|   N|                Y|          Five Stars|Works great, it a...|2015-08-31 00:00:00|\n|         US|   12081067|R2PCO0R2FKDQLD|B00I56KQV4|     383995956|Cozy Beddings 3-P...|            Home|          5|            0|          0|   N|                Y|          Five Stars|Exactly as I expe...|2015-08-31 00:00:00|\n|         US|   26317120|R3HR2Y7RR8NWL0|B00GS6ENAS|     255999883|Tools of the Trad...|            Home|          4|            0|          0|   N|                Y|          Four Stars|    met expectations|2015-08-31 00:00:00|\n|         US|   37523392|R2D2NATNTV6VBD|B00S9X17SY|     142926812|Clara Clark Premi...|            Home|          3|            0|          0|   N|                Y|        Pretty color|Very silky feelin...|2015-08-31 00:00:00|\n|         US|   36990227| RKB0AGB0GJ693|B001R1RXUG|     237680897|Honeywell HT-908 ...|            Home|          5|            0|          0|   N|                Y|          Five Stars|Works great for t...|2015-08-31 00:00:00|\n|         US|    8273344| RN6VOEZIS9SRX|B008T19WSS|     395315543|2 pcs .925 Sterli...|            Home|          5|            0|          0|   N|                Y|          Five Stars|          love these|2015-08-31 00:00:00|\n|         US|   45448526|R31I8XK53JBAQ2|B011A4X754|     751900773|Artficial Pachyve...|            Home|          4|            0|          0|   N|                Y|          Four Stars|Good length. Very...|2015-08-31 00:00:00|\n|         US|   28088591|R2R2Y989GKB6QH|B00DDIKBQO|     764331420|Pinzon Blackout C...|            Home|          5|            0|          0|   N|                Y|          Five Stars|        Works great!|2015-08-31 00:00:00|\n|         US|   20276397|R12WZKURAV2VEY|B00F3T165Q|     962537263|Rit Dye Liquid Dy...|            Home|          5|            0|          0|   N|                Y|            Love it!|Been using this f...|2015-08-31 00:00:00|\n|         US|     123327| RX2EMR0I821HW|B006C6FC6S|     279696452|The Original Slee...|            Home|          2|            0|          0|   N|                Y|           Two Stars|Ehh. Not sure why...|2015-08-31 00:00:00|\n+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\nonly showing top 20 rows\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20191213-053125_1444298189",
      "dateCreated": "Dec 13, 2019 5:31:25 AM",
      "dateStarted": "Dec 22, 2019 1:24:20 PM",
      "dateFinished": "Dec 22, 2019 1:27:35 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n# Drop duplicates and incomplete rows \u0026 count the number of records \n\nprint(home_df.count())\nhome_df \u003d home_df.dropna()\nprint(home_df.count())\nhome_df \u003d home_df.dropDuplicates()\nprint(home_df.count())",
      "user": "",
      "dateUpdated": "Dec 17, 2019 4:33:21 AM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "6221559\n6220614\n6220614\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20191213-053410_540268835",
      "dateCreated": "Dec 13, 2019 5:34:10 AM",
      "dateStarted": "Dec 17, 2019 4:28:48 AM",
      "dateFinished": "Dec 17, 2019 4:33:21 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n\n# Examine the schema\nhome_df.printSchema()",
      "user": "",
      "dateUpdated": "Dec 17, 2019 4:33:21 AM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "root\n |-- marketplace: string (nullable \u003d true)\n |-- customer_id: integer (nullable \u003d true)\n |-- review_id: string (nullable \u003d true)\n |-- product_id: string (nullable \u003d true)\n |-- product_parent: integer (nullable \u003d true)\n |-- product_title: string (nullable \u003d true)\n |-- product_category: string (nullable \u003d true)\n |-- star_rating: integer (nullable \u003d true)\n |-- helpful_votes: integer (nullable \u003d true)\n |-- total_votes: integer (nullable \u003d true)\n |-- vine: string (nullable \u003d true)\n |-- verified_purchase: string (nullable \u003d true)\n |-- review_headline: string (nullable \u003d true)\n |-- review_body: string (nullable \u003d true)\n |-- review_date: timestamp (nullable \u003d true)\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20191213-181035_509321990",
      "dateCreated": "Dec 13, 2019 6:10:35 PM",
      "dateStarted": "Dec 17, 2019 4:33:21 AM",
      "dateFinished": "Dec 17, 2019 4:33:21 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n# Create a new DataFrame for review table\nreview_df \u003d home_df.select([\"review_id\", \"customer_id\", \"product_id\", \"product_parent\", \"review_date\"])\nreview_df.show(5)",
      "user": "",
      "dateUpdated": "Dec 22, 2019 1:28:09 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "+--------------+-----------+----------+--------------+-------------------+\n|     review_id|customer_id|product_id|product_parent|        review_date|\n+--------------+-----------+----------+--------------+-------------------+\n|R1UUISQ1GKOJTI|   33670092|B00EE62UAE|     583436067|2015-08-31 00:00:00|\n|R1HOJ9WE8VCVOD|   13726692|B001APXO5C|     465035091|2015-08-31 00:00:00|\n| RDNGVXMWQN2TN|   50131396|B002HFDLCK|     136507891|2015-08-31 00:00:00|\n|R3OM9COQMVTDJ2|   16046884|B00PL9EFPQ|     631238459|2015-08-31 00:00:00|\n|R3OFUQVR4Y80Q9|   11417282|B00B5TPVQS|     190431573|2015-08-31 00:00:00|\n+--------------+-----------+----------+--------------+-------------------+\nonly showing top 5 rows\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20191213-182037_1501063016",
      "dateCreated": "Dec 13, 2019 6:20:37 PM",
      "dateStarted": "Dec 22, 2019 1:28:08 PM",
      "dateFinished": "Dec 22, 2019 1:28:09 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n# Create a new DataFrame for products\nproducts_df \u003d home_df.select([\"product_id\", \"product_title\"])\nproducts_df.show(5)",
      "user": "",
      "dateUpdated": "Dec 22, 2019 2:36:20 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "+----------+--------------------+\n|product_id|       product_title|\n+----------+--------------------+\n|B00EE62UAE|Trademark Home Po...|\n|B001APXO5C|O2-Cool 10-Inch P...|\n|B002HFDLCK|Hoover Vacuum Cle...|\n|B00PL9EFPQ|Banksy Pile of Ri...|\n|B00B5TPVQS|SkyScan Atomic Wa...|\n+----------+--------------------+\nonly showing top 5 rows\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20191213-182141_385843753",
      "dateCreated": "Dec 13, 2019 6:21:41 PM",
      "dateStarted": "Dec 22, 2019 2:36:19 PM",
      "dateFinished": "Dec 22, 2019 2:36:20 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\ndf \u003d home_df.groupBy(\u0027customer_id\u0027).count()\ndf.orderBy(\"customer_id\").select(\"customer_id\", \"count\").show()",
      "user": "",
      "dateUpdated": "Dec 22, 2019 1:29:32 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "+-----------+-----+\n|customer_id|count|\n+-----------+-----+\n|      10006|    1|\n|      10007|    1|\n|      10032|    1|\n|      10080|    1|\n|      10092|    2|\n|      10095|    1|\n|      10124|    1|\n|      10140|    1|\n|      10155|    1|\n|      10165|    2|\n|      10192|    1|\n|      10206|    1|\n|      10227|    1|\n|      10236|    1|\n|      10256|    1|\n|      10273|    1|\n|      10293|    1|\n|      10299|    1|\n|      10316|    1|\n|      10322|    1|\n+-----------+-----+\nonly showing top 20 rows\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20191213-182403_329071077",
      "dateCreated": "Dec 13, 2019 6:24:03 PM",
      "dateStarted": "Dec 22, 2019 1:28:37 PM",
      "dateFinished": "Dec 22, 2019 1:29:32 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\r\n# Create a new DataFrame for customers \r\ncustomers_df \u003d df.withColumnRenamed(\"customer_id\", \"customer_id\") \\\r\n        .withColumnRenamed(\"count\", \"customer_count\")\r\ncustomers_df.show()",
      "user": "",
      "dateUpdated": "Dec 22, 2019 1:30:31 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "+-----------+--------------+\n|customer_id|customer_count|\n+-----------+--------------+\n|   28241302|             1|\n|   15991768|             1|\n|   17067926|             7|\n|    8905239|             3|\n|   51794064|             1|\n|   33132797|             3|\n|   21325555|             1|\n|    1574612|             1|\n|   12819130|             3|\n|   44224073|             1|\n|   16679709|             1|\n|   10742726|             1|\n|   52391013|             2|\n|   38209321|            10|\n|    2545142|             1|\n|   52918362|             6|\n|   47663761|             3|\n|   25031530|            21|\n|   29476112|             1|\n|   51496479|             1|\n+-----------+--------------+\nonly showing top 20 rows\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20191213-182710_1729612367",
      "dateCreated": "Dec 13, 2019 6:27:10 PM",
      "dateStarted": "Dec 22, 2019 1:29:41 PM",
      "dateFinished": "Dec 22, 2019 1:30:31 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n# Create a new DataFrame for vine\nvine_df \u003d home_df.select([\"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\"])\nvine_df.show(5)\n",
      "user": "",
      "dateUpdated": "Dec 22, 2019 1:31:08 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "+--------------+-----------+-------------+-----------+----+\n|     review_id|star_rating|helpful_votes|total_votes|vine|\n+--------------+-----------+-------------+-----------+----+\n|R1UUISQ1GKOJTI|          1|            0|          0|   N|\n|R1HOJ9WE8VCVOD|          5|            9|          9|   N|\n| RDNGVXMWQN2TN|          5|            0|          0|   N|\n|R3OM9COQMVTDJ2|          2|            0|          0|   N|\n|R3OFUQVR4Y80Q9|          4|            0|          0|   N|\n+--------------+-----------+-------------+-----------+----+\nonly showing top 5 rows\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20191213-183245_1873820028",
      "dateCreated": "Dec 13, 2019 6:32:45 PM",
      "dateStarted": "Dec 22, 2019 1:31:07 PM",
      "dateFinished": "Dec 22, 2019 1:31:08 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n# Configuration for RDS instance\nmode\u003d\"append\"\njdbc_url \u003d \"jdbc:postgresql://home-1.c0b3aafwzqrm.us-east-2.rds.amazonaws.com:5432/homedb\"\nconfig \u003d {\"user\":\"postgres\",\n          \"password\": \"mama4847\",\n          \"driver\":\"org.postgresql.Driver\"}",
      "user": "",
      "dateUpdated": "Dec 22, 2019 2:19:36 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20191215-044552_201351320",
      "dateCreated": "Dec 15, 2019 4:45:52 AM",
      "dateStarted": "Dec 22, 2019 2:19:36 PM",
      "dateFinished": "Dec 22, 2019 2:19:36 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n# Write DataFrame to table\n\nreview_df.write.jdbc(url\u003djdbc_url, table\u003d\u0027review_id_table\u0027, mode\u003dmode, properties\u003dconfig)",
      "user": "",
      "dateUpdated": "Dec 22, 2019 2:05:13 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20191215-051630_1450314902",
      "dateCreated": "Dec 15, 2019 5:16:30 AM",
      "dateStarted": "Dec 22, 2019 1:31:34 PM",
      "dateFinished": "Dec 22, 2019 2:05:13 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n# Write DataFrame to table\n\ncustomers_df.write.jdbc(url\u003djdbc_url, table\u003d\u0027customers\u0027, mode\u003dmode, properties\u003dconfig)",
      "user": "",
      "dateUpdated": "Dec 22, 2019 2:18:39 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20191217-033226_683398005",
      "dateCreated": "Dec 17, 2019 3:32:26 AM",
      "dateStarted": "Dec 22, 2019 2:12:46 PM",
      "dateFinished": "Dec 22, 2019 2:18:39 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n# Write DataFrame to table\n\nvine_df.write.jdbc(url\u003djdbc_url, table\u003d\u0027vine_table\u0027, mode\u003dmode, properties\u003dconfig)",
      "user": "",
      "dateUpdated": "Dec 22, 2019 2:26:11 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20191217-042336_1817141010",
      "dateCreated": "Dec 17, 2019 4:23:36 AM",
      "dateStarted": "Dec 17, 2019 4:55:28 AM",
      "dateFinished": "Dec 17, 2019 5:06:53 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n# Write DataFrame to table\n\nproducts_df.write.jdbc(url\u003djdbc_url, table\u003d\u0027products\u0027, mode\u003dmode, properties\u003dconfig)",
      "user": "",
      "dateUpdated": "Dec 22, 2019 2:34:24 PM",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "",
      "id": "20191222-141135_637375659",
      "dateCreated": "Dec 22, 2019 2:11:35 PM",
      "dateStarted": "Dec 22, 2019 3:50:45 PM",
      "dateFinished": "Dec 22, 2019 3:50:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    }
  ],
  "name": "Big Data Home",
  "id": "9566f8cc530944a5be41bf0e1cfb81b6",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {},
  "info": {}
}